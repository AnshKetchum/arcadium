parameters:
  experiment_name: "moe-language-modeling-tiny"
  epochs: 1000
  checkpoint_frequency: 250
  batch_size: 8
  num_workers: 2
  sequence_length: 32
  lr: 0.001
