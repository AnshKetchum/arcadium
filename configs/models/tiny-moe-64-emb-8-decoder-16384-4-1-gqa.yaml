parameters:
  name: moe-basic-1m-64-emb-1L
  type: moe
  configuration:
    model:
      decoder_layers: 8
    decoder:
      input_dimension: 512
      output_dimension: 512
      hidden_dimension: 512
      experts: 8
      norm_eps: 1.0e-05
      attention:
        type: "grouped-query"
        num_query_heads: 8
        num_kv_heads: 2
        embedding_dimension: 512
        head_dimension: 256
  tokenizer:
    config: configs/tokenizer/basic-8192.yaml
