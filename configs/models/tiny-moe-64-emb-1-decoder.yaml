parameters:
  name: "moe-basic-1m-64-emb"
  type: "moe"
  configuration:
    model:
      decoder_layers: 1 
    decoder: 
      input_dimension: 64
      output_dimension: 64
      hidden_dimension: 64
      heads: 8
      experts: 8
      norm_eps: 1e-5
language_model:
  vocab_size: 4096